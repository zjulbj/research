
#起因
- 1 某业务改版之之后接口访问量翻了10倍(其实也不大，峰值QPS才100)
- 2 虽然做了缓存，但是频繁full gc撑爆cpu，导致接口还是很慢

#原来设计
- 1 缓存在redis内，ttl为10分钟
- 2 每个接口会从redis取全量数据，排序(频繁full gc)
- 3 10分钟缓存过期，大量请求击穿缓存，到mysql取全量数据Orz...

#应急方案
- 1 调大Xmn延迟到达old区时间，调大Xmx减小full gc速度
- 2 临时加一台机器，分摊压力
调整之后，线上环境暂时扛住，进一步调整缓存方案，从根本上解决问题。

#解决思路

- 1.缓存排行数据到redis列表，每次请求分页取。(避免每次全量取出排)
- 2.手动控制缓存过期时间，使redis中一次载入之后一直有缓存(避免大量击穿，牺牲第一批访问可用性)
- 3.缓存过期时，只允许一次缓存重载操作。(避免重复操作缓存)
- 4.外部接口永远从redis取数据，用户请求不会击穿缓存，缓存耗时更新用户是不会感知到

#时序设计

![seq.png](http://images2015.cnblogs.com/blog/712729/201608/712729-20160818235323562-46097954.png)

关键设计：
- 1 过期标记
一个简单的设置了过期时间的（k,v,ttl)信号，用来判断是否该更新redis缓存了。
和具体的缓存数据无关，所有的缓存数据原则上都不设过期时间（也可以设置一个比较长的ttl）

- 2 如果多个线程同时判断缓存过期了，怎么保证只触发一次缓存任务
```
private Map<Long, AtomicBoolean> lockMap = new ConcurrentHashMap<>();
private AtomicBoolean getLock(long ayid) {
	AtomicBoolean lock = lockMap.get(ayid);
	if (lock == null) {
		synchronized (lockMap) {
			lock = lockMap.get(ayid);
			if (lock == null) {
				lock = new AtomicBoolean(false);
				lockMap.put(ayid, lock);
			} else {
			}
		}
	}
	return lock;
}
//抢占信号
private boolean lock(long ayid) {
	AtomicBoolean lock = getLock(ayid);
	return lock.compareAndSet(false, true);
}
//释放信号
private boolean unlock(long ayid) {
	AtomicBoolean lock = getLock(ayid);
	return lock.compareAndSet(true, false);
}
//
if (lock(ayid)) {
      //抢到了，do cache
      unlock(ayid);
｝else {
     //没抢到，忽略
｝
```
- 3 分布式情况下，多个进程同时操作redis缓存怎么办
生成一个随机的临时key，存入redis后，rename到最终的key
```
String temp = "_tmp" + UUID.randomUUID().toString();
String cacheNewKeyTemp = cacheNewKey + temp;
String cacheHotKeyTemp = cacheHotKey + temp;
// cache to temp
jedis.hmset(cacheVideoKey, fields);
jedis.rpush(cacheNewKeyTemp, puidVersDefaultRank);
jedis.rpush(cacheHotKeyTemp, puidVersHotRank);
// swap
jedis.rename(cacheNewKeyTemp, cacheNewKey);
jedis.rename(cacheHotKeyTemp, cacheHotKey);
```
这个方式每个jvm 进程还是重复操作了缓存，但是简单直接，这点开销还是能接受。
水平扩展时会增加重复次数，如果进一步优化可以引入分布式锁或者分布式队列

#总结改进
- 1 10分钟内数据是不变的，可以本机基于查询参数做个lru缓存，减少redis的开销
- 2 总体思路是缓存快要失效时，让一个后台任务去预先准备好缓存，到了时间切换下指针。
- 3 因为原来的业务是基于redis做的,所以这里基于redis来做。但这个思路不一定必须要用redis
